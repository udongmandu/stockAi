import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import os
from openai import OpenAI

st.set_page_config(page_title="KRX ë‰´ìŠ¤-AI ìë™í™”", layout="centered")

KRX_FILE = "krx_temp.xls"

st.title("KRX ìƒì¥ì¢…ëª© ë‰´ìŠ¤ + AI ë¶„ì„ ìë™í™”")

# API í‚¤ ì…ë ¥
if 'api_key' not in st.session_state:
    st.session_state.api_key = None

def submit_api_key():
    st.session_state.api_key = st.session_state.api_key_input

if st.session_state.api_key is None:
    st.text_input("OpenAI API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”", type="password", key="api_key_input", on_change=submit_api_key)
else:
    st.success("âœ… API í‚¤ ì…ë ¥ ì™„ë£Œ")

# ë‰´ìŠ¤ ê¸°ì‚¬ ê°œìˆ˜ ì…ë ¥
news_count = st.number_input("ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê¸°ì‚¬ ê°œìˆ˜ ì…ë ¥", min_value=1, max_value=50, value=15, step=1)

# KRX íŒŒì¼ ì¡´ì¬ ì—¬ë¶€ ì²´í¬
file_exists = os.path.isfile(KRX_FILE)

if file_exists and (st.session_state.api_key is not None):
    st.success(f"âœ… '{KRX_FILE}' íŒŒì¼ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    if not file_exists:
        st.warning(
            "âŒ '{KRX_FILE}' íŒŒì¼ì´ í´ë”ì— ì—†ìŠµë‹ˆë‹¤.\n"
            "https://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13\n"
            "ìœ„ ì£¼ì†Œì—ì„œ íŒŒì¼ ë°›ì€ í›„\n"
            "íŒŒì¼ -> ë‚´ë³´ë‚´ê¸° -> íŒŒì¼ í˜•ì‹ ë³€ê²½ -> Excel 97 - 2003 í†µí•© ë¬¸ì„œë¡œ ë‚´ë³´ë‚´ê¸°\n"
            "'krx_temp.xls'ë¡œ ì´ë¦„ì„ ë³€ê²½í•˜ì—¬ ì´ íŒŒì´ì¬ íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ìœ„ì¹˜ì‹œì¼œ ì£¼ì„¸ìš”."
        )
    if st.session_state.api_key is None:
        st.warning("âŒ OpenAI API í‚¤ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.")

start_btn_disabled = not (file_exists and st.session_state.api_key is not None)
start = st.button("ğŸš€ ì‹œì‘", disabled=start_btn_disabled)

if start:
    with st.spinner("AI ë¶„ì„ ë° ë°ì´í„° ì²˜ë¦¬ì¤‘..."):
        # ì—‘ì…€ íŒŒì¼ ì½ê¸°
        try:
            try:
                df_stocklist = pd.read_excel(KRX_FILE, dtype=str, engine='xlrd')
            except Exception:
                df_stocklist = pd.read_excel(KRX_FILE, dtype=str)
            stock_names = set(df_stocklist['íšŒì‚¬ëª…'].dropna())
            st.info(f"ìƒì¥ì¢…ëª© ìˆ˜: {len(stock_names)}ê°œ")
        except Exception as e:
            st.error(f"ì—‘ì…€ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
            st.stop()

        # ì¢…ëª©ëª… í¬í•¨ í™•ì¸ í•¨ìˆ˜
        def find_stock_in_text(text, stock_names):
            if not isinstance(text, str):
                return None
            for name in stock_names:
                if name in text:
                    return name
            return None

        # ì—¬ëŸ¬ í˜ì´ì§€ í¬ë¡¤ë§
        news_results = []
        cnt = 0
        page = 1
        count_limit = news_count

        while cnt < count_limit:
            news_url = f"https://finance.naver.com/news/mainnews.naver?&page={page}"
            try:
                res = requests.get(news_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
                soup = BeautifulSoup(res.text, 'html.parser')
            except Exception as e:
                st.error(f"ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì˜¤ë¥˜ (í˜ì´ì§€ {page}): {e}")
                break

            articles = soup.select('ul.newsList > li')
            if not articles:
                break

            for li in articles:
                if cnt >= count_limit:
                    break
                article_subject = li.select_one('dd.articleSubject a')
                article_summary = li.select_one('dd.articleSummary')
                if article_subject:
                    title = article_subject.get_text(strip=True)
                    link = article_subject['href']
                    if not link.startswith('http'):
                        link = "https://finance.naver.com" + link
                    summary = article_summary.get_text(" ", strip=True) if article_summary else ""
                    stock = find_stock_in_text(title, stock_names) or find_stock_in_text(summary, stock_names)
                    if stock:
                        news_results.append({
                            'ì¢…ëª©ëª…': stock,
                            'ë‰´ìŠ¤': title,
                            'ë§í¬': link,
                            'ìš”ì•½': summary
                        })
                        cnt += 1

            page += 1

        if len(news_results) == 0:
            st.warning("ë‰´ìŠ¤ì—ì„œ ìƒì¥ì¢…ëª©ëª…ì´ í¬í•¨ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
            st.stop()

        news_df = pd.DataFrame(news_results).drop_duplicates(['ì¢…ëª©ëª…', 'ë‰´ìŠ¤'])

        # OpenAI API í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
        openai_api_key = st.session_state.api_key
        client = OpenAI(api_key=openai_api_key)

        # AI ë‰´ìŠ¤ ë¶„ì„ í•¨ìˆ˜
        def classify_news(title, summary):
            news_text = f"{title} {summary}"
            prompt = f"""ì•„ë˜ ë‰´ìŠ¤ê°€ í•´ë‹¹ ê¸°ì—…ì— í˜¸ì¬(ìƒìŠ¹ ê°€ëŠ¥ì„±), ì•…ì¬(í•˜ë½ ê°€ëŠ¥ì„±), ì¤‘ë¦½ ì¤‘ ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ì§€ í•œê¸€ë¡œ ë‹¨ë‹µ(í˜¸ì¬/ì•…ì¬/ì¤‘ë¦½)ê³¼ ì´ìœ (1ë¬¸ì¥)ë¥¼ ì•Œë ¤ì¤˜.
ë‰´ìŠ¤: {news_text}"""
            try:
                response = client.chat.completions.create(
                    model="gpt-3.5-turbo",
                    messages=[{"role": "user", "content": prompt}],
                    max_tokens=100,
                    temperature=0
                )
                answer = response.choices[0].message.content.strip()
                if answer.startswith("í˜¸ì¬"):
                    tag = "í˜¸ì¬"
                elif answer.startswith("ì•…ì¬"):
                    tag = "ì•…ì¬"
                else:
                    tag = "ì¤‘ë¦½"
                return tag, answer
            except Exception as e:
                return "ë¶„ì„ë¶ˆê°€", f"API ì˜¤ë¥˜: {e}"

        news_df['ë‰´ìŠ¤íŒë³„'] = ""
        news_df['AIì„¤ëª…'] = ""

        for idx, row in news_df.iterrows():
            tag, explanation = classify_news(row['ë‰´ìŠ¤'], row['ìš”ì•½'])
            news_df.at[idx, 'ë‰´ìŠ¤íŒë³„'] = tag
            news_df.at[idx, 'AIì„¤ëª…'] = explanation
            st.info(f"[AIë¶„ì„]{row['ì¢…ëª©ëª…']}: {row['ë‰´ìŠ¤']} => {tag}")
            time.sleep(0.5)  # API ê³¼ë¶€í•˜ ë°©ì§€

        # ì¬ë¬´ ë°ì´í„° ì¡°íšŒ í•¨ìˆ˜
        def get_code_from_name(stock_name):
            try:
                matched_rows = df_stocklist[df_stocklist['íšŒì‚¬ëª…'] == stock_name]
                if not matched_rows.empty:
                    code = matched_rows.iloc[0]['ì¢…ëª©ì½”ë“œ']
                    return str(code).zfill(6)
                return None
            except:
                return None

        finance_results = []
        unique_stocks = set(news_df['ì¢…ëª©ëª…'])
        for stock in unique_stocks:
            code = get_code_from_name(stock)
            if code is None:
                st.warning(f"{stock} ì¢…ëª©ì½”ë“œ ë¯¸ë°œê²¬, ì¬ë¬´ ë°ì´í„° ìƒëµ")
                continue
            url = f"https://finance.naver.com/item/main.nhn?code={code}"
            try:
                res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
                soup = BeautifulSoup(res.text, 'html.parser')
            except Exception as e:
                st.warning(f"{stock} ì¬ë¬´ ë°ì´í„° ìš”ì²­ ì‹¤íŒ¨: {e}")
                continue

            price = 'N/A'
            try:
                price_tag = soup.select_one('p.no_today span.blind')
                if price_tag:
                    price = price_tag.get_text(strip=True).replace(',', '')
            except:
                pass

            per = pbr = roe = eps = 'N/A'
            table = soup.select_one('table.tb_type1_ifrs')
            if table:
                try:
                    rows = table.select('tr')
                    for row in rows:
                        th = row.find('th')
                        if not th:
                            continue
                        th_text = th.get_text(strip=True)
                        tds = row.find_all('td')
                        val = next((td.get_text(strip=True) for td in tds if td.get_text(strip=True)), 'N/A')
                        if 'PER' in th_text:
                            per = val
                        elif 'PBR' in th_text:
                            pbr = val
                        elif 'ROE' in th_text:
                            roe = val
                        elif 'EPS' in th_text:
                            eps = val
                except:
                    pass

            finance_results.append({
                'ì¢…ëª©ëª…': stock,
                'PER': per,
                'PBR': pbr,
                'ROE': roe,
                'EPS': eps,
                'í˜„ì¬ê°€': price
            })

        df_finance = pd.DataFrame(finance_results)

        def safe_float(val):
            try:
                return float(str(val).replace(',', ''))
            except:
                return None

        if not df_finance.empty:
            df_finance['PER_f'] = df_finance['PER'].apply(safe_float)
            df_finance['ROE_f'] = df_finance['ROE'].apply(safe_float)
            df_finance['EPS_f'] = df_finance['EPS'].apply(safe_float)
            df_finance['í˜„ì¬ê°€_f'] = df_finance['í˜„ì¬ê°€'].apply(safe_float)
            df_finance['ì˜ˆìƒì£¼ê°€'] = df_finance['EPS_f'] * 10
            df_finance['ì˜ˆìƒì£¼ê°€_í‘œì‹œ'] = df_finance['ì˜ˆìƒì£¼ê°€'].apply(lambda x: f"{x:,.0f}" if pd.notnull(x) else 'N/A')
            df_finance['ìƒìŠ¹ì—¬ë ¥'] = df_finance['ì˜ˆìƒì£¼ê°€'] - df_finance['í˜„ì¬ê°€_f']

            def format_sign(x):
                if pd.isnull(x):
                    return 'N/A'
                if x > 0:
                    return f"+{x:,.0f}"
                elif x < 0:
                    return f"{x:,.0f}"
                else:
                    return "0"

            df_finance['ìƒìŠ¹ì—¬ë ¥_í‘œì‹œ'] = df_finance['ìƒìŠ¹ì—¬ë ¥'].apply(format_sign)
            df_finance['ROE'] = df_finance['ROE'].apply(lambda x: f"{x}%" if x != 'N/A' and not str(x).endswith('%') else x)
            df_finance['í˜„ì¬ê°€_í‘œì‹œ'] = df_finance['í˜„ì¬ê°€_f'].apply(lambda x: f"{x:,.0f}" if pd.notnull(x) else 'N/A')

        news_df['ì¢…ëª©ëª…'] = news_df['ì¢…ëª©ëª…'].astype(str)
        df_finance['ì¢…ëª©ëª…'] = df_finance['ì¢…ëª©ëª…'].astype(str)
        result_table = pd.merge(news_df, df_finance, on='ì¢…ëª©ëª…', how='left')
        result_table['ì˜¤ëŠ˜ê¸°ì‚¬'] = result_table['ë‰´ìŠ¤íŒë³„']

        show_cols = ['ì¢…ëª©ëª…', 'ë‰´ìŠ¤', 'ìš”ì•½', 'ë‰´ìŠ¤íŒë³„', 'AIì„¤ëª…',
                     'ì˜ˆìƒì£¼ê°€_í‘œì‹œ', 'í˜„ì¬ê°€_í‘œì‹œ', 'ìƒìŠ¹ì—¬ë ¥_í‘œì‹œ', 'ì˜¤ëŠ˜ê¸°ì‚¬', 'ë§í¬']

        for col in ['ì˜ˆìƒì£¼ê°€_í‘œì‹œ', 'í˜„ì¬ê°€_í‘œì‹œ', 'ìƒìŠ¹ì—¬ë ¥_í‘œì‹œ']:
            if col not in result_table.columns:
                result_table[col] = 'N/A'

        final_df = result_table[show_cols].rename(columns={
            'ì˜ˆìƒì£¼ê°€_í‘œì‹œ': 'ì˜ˆìƒì£¼ê°€',
            'í˜„ì¬ê°€_í‘œì‹œ': 'í˜„ì¬ê°€',
            'ìƒìŠ¹ì—¬ë ¥_í‘œì‹œ': 'ì˜ˆìƒì£¼ê°€-í˜„ì¬ê°€'
        })

        # ì „ì²´ ë‰´ìŠ¤ ë¯¸ë¦¬ë³´ê¸°
        st.write("### ğŸ“° ì˜¤ëŠ˜ ì¢…ëª© ë‰´ìŠ¤ ")

        def color_news(tag):
            if tag == 'í˜¸ì¬':
                return 'color: blue; font-weight: bold;'
            elif tag == 'ì•…ì¬':
                return 'color: red; font-weight: bold;'
            elif tag == 'ì¤‘ë¦½':
                return 'color: gray;'
            else:
                return ''

        def highlight_news(row):
            color = color_news(row['ë‰´ìŠ¤íŒë³„'])
            return [color] * len(row)

        styled_df = final_df.style.apply(highlight_news, axis=1)
        st.dataframe(styled_df, use_container_width=True)

        # ê°€ì¥ ê¸°ëŒ€ë˜ëŠ” ì¢…ëª© TOP 5 í‘œì‹œ
        expecting_stocks = final_df[(final_df['ë‰´ìŠ¤íŒë³„'] == 'í˜¸ì¬') & (final_df['ì˜ˆìƒì£¼ê°€-í˜„ì¬ê°€'] != 'N/A')]

        def to_float(x):
            try:
                return float(str(x).replace(',', '').replace('+',''))
            except:
                return -9999999

        expecting_stocks = expecting_stocks.copy()
        expecting_stocks['ìƒìŠ¹ì—¬ë ¥_ìˆ«ì'] = expecting_stocks['ì˜ˆìƒì£¼ê°€-í˜„ì¬ê°€'].apply(to_float)
        expecting_stocks = expecting_stocks.sort_values('ìƒìŠ¹ì—¬ë ¥_ìˆ«ì', ascending=False)
        top5_expect = expecting_stocks.head(5)

        if not top5_expect.empty:
            st.write("### ğŸš€ ê°€ì¥ ê¸°ëŒ€ë˜ëŠ” ì¢…ëª© TOP 5 (í˜¸ì¬ + ìƒìŠ¹ì—¬ë ¥ ë†’ì€ ìˆœ)")
            st.dataframe(top5_expect[[
                'ì¢…ëª©ëª…', 'ë‰´ìŠ¤', 'ìš”ì•½', 'ë‰´ìŠ¤íŒë³„', 'AIì„¤ëª…', 'ì˜ˆìƒì£¼ê°€', 'í˜„ì¬ê°€', 'ì˜ˆìƒì£¼ê°€-í˜„ì¬ê°€', 'ë§í¬'
            ]])
        else:
            st.info("í˜¸ì¬ì— í•´ë‹¹í•˜ëŠ” ì¢…ëª©ì´ ì—†ê±°ë‚˜ ìƒìŠ¹ì—¬ë ¥ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

        # HTML ë‹¤ìš´ë¡œë“œ ë²„íŠ¼
        def to_html_download(df):
            html = df.to_html(index=False)
            b64 = html.encode('utf-8')
            return b64

        b64_html = to_html_download(final_df)
        st.download_button(
            label="ğŸ“¥ HTML ë‹¤ìš´ë¡œë“œ",
            data=b64_html,
            file_name="stock_news_ai_result.html",
            mime="text/html"
        )
