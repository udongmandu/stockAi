import streamlit as st
import pandas as pd
import requests
from bs4 import BeautifulSoup
import time
import os
import json
from datetime import datetime
from openai import OpenAI
import plotly.graph_objects as go
from dotenv import load_dotenv

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

KRX_FILE = "krx_temp.xls"
CACHE_FILE = "cache_news_ai.json"

st.set_page_config(page_title="KRX ë‰´ìŠ¤-AI ìžë™í™”", layout="centered")
st.title("KRX ìƒìž¥ì¢…ëª© ë‰´ìŠ¤ + AI ë¶„ì„ ìžë™í™”")

# í™˜ê²½ë³€ìˆ˜ì—ì„œ API í‚¤ ì½ê¸°
api_key_env = os.getenv("OPENAI_API_KEY")

if 'api_key' not in st.session_state:
    st.session_state.api_key = api_key_env

def submit_api_key():
    st.session_state.api_key = st.session_state.api_key_input

if st.session_state.api_key is None:
    st.text_input("API í‚¤ê°€ ìžˆëŠ” ENV íŒŒì¼ì„ ë°›ì•„ ì£¼ì„¸ìš”.", type="password", key="api_key_input", on_change=submit_api_key)
else:
    st.success("âœ… ENV íŒŒì¼ ì¸ì‹ ì™„ë£Œ")

news_count = st.number_input("ê°€ì ¸ì˜¬ ë‰´ìŠ¤ ê¸°ì‚¬ ê°œìˆ˜ ìž…ë ¥", min_value=1, max_value=50, value=15, step=1)
today_only = st.checkbox("ê¸ˆì¼ ê¸°ì‚¬ë§Œ", value=False)

file_exists = os.path.isfile(KRX_FILE)
if file_exists and (st.session_state.api_key is not None):
    st.success(f"âœ… '{KRX_FILE}' íŒŒì¼ì´ í™•ì¸ë˜ì—ˆìŠµë‹ˆë‹¤.")
else:
    if not file_exists:
        st.warning(
            "âŒ '{KRX_FILE}' íŒŒì¼ì´ í´ë”ì— ì—†ìŠµë‹ˆë‹¤.\n"
            "https://kind.krx.co.kr/corpgeneral/corpList.do?method=download&searchType=13\n"
            "ìœ„ ì£¼ì†Œì—ì„œ íŒŒì¼ ë°›ì€ í›„\n"
            "íŒŒì¼ -> ë‚´ë³´ë‚´ê¸° -> íŒŒì¼ í˜•ì‹ ë³€ê²½ -> Excel 97 - 2003 í†µí•© ë¬¸ì„œë¡œ ë‚´ë³´ë‚´ê¸°\n"
            "'krx_temp.xls'ë¡œ ì´ë¦„ì„ ë³€ê²½í•˜ì—¬ ì´ íŒŒì´ì¬ íŒŒì¼ê³¼ ê°™ì€ í´ë”ì— ìœ„ì¹˜ì‹œì¼œ ì£¼ì„¸ìš”."
        )
    if st.session_state.api_key is None:
        st.warning("âŒ OpenAI API í‚¤ë¥¼ ìž…ë ¥í•´ì£¼ì„¸ìš”.")

start_btn_disabled = not (file_exists and st.session_state.api_key is not None)
if 'is_running' not in st.session_state:
    st.session_state.is_running = False
start = st.button("ðŸš€ ì‹œìž‘", disabled=start_btn_disabled or st.session_state.is_running)

def find_stock_in_text(text, stock_names):
    if not isinstance(text, str):
        return None
    for name in stock_names:
        if name in text:
            return name
    return None

def classify_news(title, summary):
    news_text = f"{title} {summary}"
    prompt = f"""ì•„ëž˜ ë‰´ìŠ¤ê°€ í•´ë‹¹ ê¸°ì—…ì— í˜¸ìž¬(ìƒìŠ¹ ê°€ëŠ¥ì„±), ì•…ìž¬(í•˜ë½ ê°€ëŠ¥ì„±), ì¤‘ë¦½ ì¤‘ ì–´ë–¤ ì˜í–¥ì„ ë¯¸ì¹ ì§€ í•œê¸€ë¡œ ë‹¨ë‹µ(í˜¸ìž¬/ì•…ìž¬/ì¤‘ë¦½)ê³¼ ì´ìœ (1ë¬¸ìž¥)ë¥¼ ì•Œë ¤ì¤˜.
ë‰´ìŠ¤: {news_text}"""
    try:
        response = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            max_tokens=100,
            temperature=0
        )
        answer = response.choices[0].message.content.strip()
        if answer.startswith("í˜¸ìž¬"):
            tag = "í˜¸ìž¬"
        elif answer.startswith("ì•…ìž¬"):
            tag = "ì•…ìž¬"
        else:
            tag = "ì¤‘ë¦½"
        return tag, answer
    except Exception as e:
        return "ë¶„ì„ë¶ˆê°€", f"API ì˜¤ë¥˜: {e}"

def get_code_from_name(stock_name):
    try:
        matched_rows = df_stocklist[df_stocklist['íšŒì‚¬ëª…'] == stock_name]
        if not matched_rows.empty:
            code = matched_rows.iloc[0]['ì¢…ëª©ì½”ë“œ']
            return str(code).zfill(6)
        return None
    except:
        return None

def safe_float(val):
    try:
        return float(str(val).replace(',', ''))
    except:
        return None

def crawl_naver_daily_price(stock_code, max_days=60):
    base_url = "https://finance.naver.com/item/sise_day.naver"
    all_rows = []
    page = 1

    while True:
        params = {'code': stock_code, 'page': page}
        res = requests.get(base_url, params=params, headers={'User-Agent': 'Mozilla/5.0'})
        soup = BeautifulSoup(res.text, 'html.parser')

        table = soup.find('table', class_='type2')
        if not table:
            break

        rows = table.find_all('tr')
        data_rows = [row for row in rows if len(row.find_all('td')) == 7]
        if not data_rows:
            break

        for row in data_rows:
            cols = row.find_all('td')
            date = cols[0].get_text(strip=True).replace('.', '-')
            close = cols[1].get_text(strip=True).replace(',', '')
            open_price = cols[3].get_text(strip=True).replace(',', '')
            high = cols[4].get_text(strip=True).replace(',', '')
            low = cols[5].get_text(strip=True).replace(',', '')
            volume = cols[6].get_text(strip=True).replace(',', '')
            all_rows.append({
                'ë‚ ì§œ': date,
                'ì¢…ê°€': float(close) if close else None,
                'ì‹œê°€': float(open_price) if open_price else None,
                'ê³ ê°€': float(high) if high else None,
                'ì €ê°€': float(low) if low else None,
                'ê±°ëž˜ëŸ‰': int(volume) if volume else None
            })

            if len(all_rows) >= max_days:
                break

        if len(all_rows) >= max_days:
            break

        page += 1

    df = pd.DataFrame(all_rows)
    df = df.dropna(subset=['ì¢…ê°€'])
    df['ë‚ ì§œ'] = pd.to_datetime(df['ë‚ ì§œ'])
    df = df.sort_values('ë‚ ì§œ')
    df.reset_index(drop=True, inplace=True)
    return df

def plot_bollinger_20day(df_price, stock_name, stock_code, key=None, news_dates=None):
    if len(df_price) < 20:
        st.warning(f"{stock_name} ì‹œì„¸ ë°ì´í„°ê°€ ë¶€ì¡±í•´ ë³¼ë¦°ì € ë°´ë“œë¥¼ ê·¸ë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        return

    window = 20
    df_price[f'MA{window}'] = df_price['ì¢…ê°€'].rolling(window=window).mean()
    df_price[f'STD{window}'] = df_price['ì¢…ê°€'].rolling(window=window).std()
    df_price[f'Upper{window}'] = df_price[f'MA{window}'] + 2 * df_price[f'STD{window}']
    df_price[f'Lower{window}'] = df_price[f'MA{window}'] - 2 * df_price[f'STD{window}']

    dates = df_price['ë‚ ì§œ']

    st.write(f"### {stock_name} 20ì¼ ë³¼ë¦°ì € ë°´ë“œ")
    st.markdown(f"[ì£¼ê°€ ìƒì„¸ ë³´ê¸°](https://finance.naver.com/item/main.nhn?code={stock_code})")

    fig = go.Figure(
        data=[
            go.Scatter(x=dates, y=df_price['ì¢…ê°€'], mode='lines', name='ì¢…ê°€'),
            go.Scatter(x=dates, y=df_price[f'MA{window}'], mode='lines', name=f'MA{window}'),
            go.Scatter(x=dates, y=df_price[f'Upper{window}'], mode='lines', name='ìƒë‹¨ ë°´ë“œ'),
            go.Scatter(x=dates, y=df_price[f'Lower{window}'], mode='lines', name='í•˜ë‹¨ ë°´ë“œ', fill='tonexty', fillcolor='rgba(200,200,200,0.2)'),
        ],
        layout=go.Layout(
            xaxis_title="ë‚ ì§œ",
            yaxis_title="ê°€ê²©",
            xaxis=dict(range=[dates.min(), dates.max()]),
            yaxis=dict(autorange=True),
        )
    )

    if news_dates:
        for nd in news_dates:
            try:
                nd_dt = pd.to_datetime(nd)
                price_row = df_price[df_price['ë‚ ì§œ'] == nd_dt]
                if not price_row.empty:
                    price = price_row.iloc[0]['ì¢…ê°€']
                    fig.add_trace(go.Scatter(
                        x=[nd_dt],
                        y=[price],
                        mode='markers+text',
                        marker=dict(color='orange', size=12, symbol='star'),
                        text=["ðŸ“° ë‰´ìŠ¤"],
                        textposition="top center",
                        name=f"ë‰´ìŠ¤({nd})",
                        showlegend=False
                    ))
            except Exception:
                pass

    st.plotly_chart(fig, use_container_width=True, key=key)


if start:
    st.session_state.is_running = True
    try:
        try:
            df_stocklist = pd.read_excel(KRX_FILE, dtype=str, engine='xlrd')
        except Exception:
            df_stocklist = pd.read_excel(KRX_FILE, dtype=str)
        stock_names = set(df_stocklist['íšŒì‚¬ëª…'].dropna())
        st.info(f"ìƒìž¥ì¢…ëª© ìˆ˜: {len(stock_names)}ê°œ")
    except Exception as e:
        st.error(f"ì—‘ì…€ íŒŒì¼ ì½ê¸° ì˜¤ë¥˜: {e}")
        st.session_state.is_running = False
        st.stop()

    news_results = []
    cnt = 0
    page = 1
    count_limit = news_count
    today_str = datetime.today().strftime("%Y-%m-%d")

    while cnt < count_limit:
        news_url = f"https://finance.naver.com/news/mainnews.naver?&page={page}"
        try:
            res = requests.get(news_url, headers={'User-Agent': 'Mozilla/5.0'}, timeout=10)
            soup = BeautifulSoup(res.text, 'html.parser')
        except Exception as e:
            st.error(f"ë„¤ì´ë²„ ë‰´ìŠ¤ í¬ë¡¤ë§ ì˜¤ë¥˜ (íŽ˜ì´ì§€ {page}): {e}")
            break

        articles = soup.select('ul.newsList > li')
        if not articles:
            break

        for li in articles:
            if cnt >= count_limit:
                break
            article_subject = li.select_one('dd.articleSubject a')
            article_summary = li.select_one('dd.articleSummary')
            article_date_tag = li.select_one('dd.articleSummary span.wdate')

            if article_subject and article_date_tag:
                news_date = article_date_tag.get_text(strip=True)
                news_date_only = news_date.split(' ')[0]

                if today_only and news_date_only != today_str:
                    break

                title = article_subject.get_text(strip=True)
                link = article_subject['href']
                if not link.startswith('http'):
                    link = "https://finance.naver.com" + link
                summary = article_summary.get_text(" ", strip=True) if article_summary else ""
                stock = find_stock_in_text(title, stock_names) or find_stock_in_text(summary, stock_names)
                if stock:
                    news_results.append({
                        'ì¢…ëª©ëª…': stock,
                        'ë‰´ìŠ¤': title,
                        'ë§í¬': link,
                        'ìš”ì•½': summary,
                        'ë‰´ìŠ¤ë‚ ì§œ': news_date_only
                    })
                    cnt += 1

        else:
            page += 1
            continue
        break

    if len(news_results) == 0:
        st.warning("ë‰´ìŠ¤ì—ì„œ ìƒìž¥ì¢…ëª©ëª…ì´ í¬í•¨ëœ ê¸°ì‚¬ê°€ ì—†ìŠµë‹ˆë‹¤.")
        st.session_state.is_running = False
        st.stop()

    news_df = pd.DataFrame(news_results).drop_duplicates(['ì¢…ëª©ëª…', 'ë‰´ìŠ¤'])

    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, 'r', encoding='utf-8') as f:
            cache_dict = json.load(f)
    else:
        cache_dict = {}

    openai_api_key = st.session_state.api_key
    client = OpenAI(api_key=openai_api_key)

    news_df['ë‰´ìŠ¤íŒë³„'] = ""
    news_df['AIì„¤ëª…'] = ""

    for idx, row in news_df.iterrows():
        cached = cache_dict.get(row['ë‰´ìŠ¤'])
        if cached:
            if today_only and cached.get('ë‰´ìŠ¤ë‚ ì§œ') != today_str:
                tag, explanation = classify_news(row['ë‰´ìŠ¤'], row['ìš”ì•½'])
                news_df.at[idx, 'ë‰´ìŠ¤íŒë³„'] = tag
                news_df.at[idx, 'AIì„¤ëª…'] = explanation
                st.info(f"[AIë¶„ì„]{row['ì¢…ëª©ëª…']}: {row['ë‰´ìŠ¤']} => {tag}")
                time.sleep(0.5)
                cache_dict[row['ë‰´ìŠ¤']] = {
                    'ë‰´ìŠ¤íŒë³„': tag,
                    'AIì„¤ëª…': explanation,
                    'ë‰´ìŠ¤ë‚ ì§œ': row['ë‰´ìŠ¤ë‚ ì§œ']
                }
            else:
                news_df.at[idx, 'ë‰´ìŠ¤íŒë³„'] = cached['ë‰´ìŠ¤íŒë³„']
                news_df.at[idx, 'AIì„¤ëª…'] = cached['AIì„¤ëª…']
                st.info(f"[ìºì‹œ] {row['ì¢…ëª©ëª…']}: {row['ë‰´ìŠ¤']} => {cached['ë‰´ìŠ¤íŒë³„']}")
        else:
            tag, explanation = classify_news(row['ë‰´ìŠ¤'], row['ìš”ì•½'])
            news_df.at[idx, 'ë‰´ìŠ¤íŒë³„'] = tag
            news_df.at[idx, 'AIì„¤ëª…'] = explanation
            st.info(f"[AIë¶„ì„]{row['ì¢…ëª©ëª…']}: {row['ë‰´ìŠ¤']} => {tag}")
            time.sleep(0.5)
            cache_dict[row['ë‰´ìŠ¤']] = {
                'ë‰´ìŠ¤íŒë³„': tag,
                'AIì„¤ëª…': explanation,
                'ë‰´ìŠ¤ë‚ ì§œ': row['ë‰´ìŠ¤ë‚ ì§œ']
            }

    with open(CACHE_FILE, 'w', encoding='utf-8') as f:
        json.dump(cache_dict, f, ensure_ascii=False, indent=2)

    finance_results = []
    unique_stocks = set(news_df['ì¢…ëª©ëª…'])
    for stock in unique_stocks:
        code = get_code_from_name(stock)
        if code is None:
            st.warning(f"{stock} ì¢…ëª©ì½”ë“œ ë¯¸ë°œê²¬, ìž¬ë¬´ ë°ì´í„° ìƒëžµ")
            continue
        url = f"https://finance.naver.com/item/main.nhn?code={code}"
        try:
            res = requests.get(url, headers={'User-Agent': 'Mozilla/5.0'})
            soup = BeautifulSoup(res.text, 'html.parser')
        except Exception as e:
            st.warning(f"{stock} ìž¬ë¬´ ë°ì´í„° ìš”ì²­ ì‹¤íŒ¨: {e}")
            continue

        price = 'N/A'
        try:
            price_tag = soup.select_one('p.no_today span.blind')
            if price_tag:
                price = price_tag.get_text(strip=True).replace(',', '')
        except:
            pass

        per = pbr = roe = eps = 'N/A'
        table = soup.select_one('table.tb_type1_ifrs')
        if table:
            try:
                rows = table.select('tr')
                for row in rows:
                    th = row.find('th')
                    if not th:
                        continue
                    th_text = th.get_text(strip=True)
                    tds = row.find_all('td')
                    val = next((td.get_text(strip=True) for td in tds if td.get_text(strip=True)), 'N/A')
                    if 'PER' in th_text:
                        per = val
                    elif 'PBR' in th_text:
                        pbr = val
                    elif 'ROE' in th_text:
                        roe = val
                    elif 'EPS' in th_text:
                        eps = val
            except:
                pass

        finance_results.append({
            'ì¢…ëª©ëª…': stock,
            'PER': per,
            'PBR': pbr,
            'ROE': roe,
            'EPS': eps,
            'í˜„ìž¬ê°€': price
        })

    df_finance = pd.DataFrame(finance_results)

    if not df_finance.empty:
        df_finance['PER_f'] = df_finance['PER'].apply(safe_float)
        df_finance['ROE_f'] = df_finance['ROE'].apply(safe_float)
        df_finance['EPS_f'] = df_finance['EPS'].apply(safe_float)
        df_finance['í˜„ìž¬ê°€_f'] = df_finance['í˜„ìž¬ê°€'].apply(safe_float)
        df_finance['ì˜ˆìƒì£¼ê°€'] = df_finance['EPS_f'] * 10
        df_finance['ì˜ˆìƒì£¼ê°€_í‘œì‹œ'] = df_finance['ì˜ˆìƒì£¼ê°€'].apply(lambda x: f"{x:,.0f}" if pd.notnull(x) else 'N/A')
        df_finance['ìƒìŠ¹ì—¬ë ¥'] = df_finance['ì˜ˆìƒì£¼ê°€'] - df_finance['í˜„ìž¬ê°€_f']

        def format_sign(x):
            if pd.isnull(x):
                return 'N/A'
            if x > 0:
                return f"+{x:,.0f}"
            elif x < 0:
                return f"{x:,.0f}"
            else:
                return "0"

        df_finance['ìƒìŠ¹ì—¬ë ¥_í‘œì‹œ'] = df_finance['ìƒìŠ¹ì—¬ë ¥'].apply(format_sign)
        df_finance['ROE'] = df_finance['ROE'].apply(lambda x: f"{x}%" if x != 'N/A' and not str(x).endswith('%') else x)
        df_finance['í˜„ìž¬ê°€_í‘œì‹œ'] = df_finance['í˜„ìž¬ê°€_f'].apply(lambda x: f"{x:,.0f}" if pd.notnull(x) else 'N/A')

    news_df['ì¢…ëª©ëª…'] = news_df['ì¢…ëª©ëª…'].astype(str)
    df_finance['ì¢…ëª©ëª…'] = df_finance['ì¢…ëª©ëª…'].astype(str)
    result_table = pd.merge(news_df, df_finance, on='ì¢…ëª©ëª…', how='left')
    result_table['ì˜¤ëŠ˜ê¸°ì‚¬'] = result_table['ë‰´ìŠ¤íŒë³„']

    show_cols = ['ì¢…ëª©ëª…', 'ë‰´ìŠ¤', 'ìš”ì•½', 'ë‰´ìŠ¤ë‚ ì§œ', 'ë‰´ìŠ¤íŒë³„', 'AIì„¤ëª…',
                 'ì˜ˆìƒì£¼ê°€_í‘œì‹œ', 'í˜„ìž¬ê°€_í‘œì‹œ', 'ìƒìŠ¹ì—¬ë ¥_í‘œì‹œ', 'ì˜¤ëŠ˜ê¸°ì‚¬', 'ë§í¬']

    for col in ['ì˜ˆìƒì£¼ê°€_í‘œì‹œ', 'í˜„ìž¬ê°€_í‘œì‹œ', 'ìƒìŠ¹ì—¬ë ¥_í‘œì‹œ']:
        if col not in result_table.columns:
            result_table[col] = 'N/A'

    final_df = result_table[show_cols].rename(columns={
        'ì˜ˆìƒì£¼ê°€_í‘œì‹œ': 'ì˜ˆìƒì£¼ê°€',
        'í˜„ìž¬ê°€_í‘œì‹œ': 'í˜„ìž¬ê°€',
        'ìƒìŠ¹ì—¬ë ¥_í‘œì‹œ': 'ì˜ˆìƒì£¼ê°€-í˜„ìž¬ê°€'
    })

    def color_news(tag):
        if tag == 'í˜¸ìž¬':
            return 'color: red; font-weight: bold;'
        elif tag == 'ì•…ìž¬':
            return 'color: blue; font-weight: bold;'
        elif tag == 'ì¤‘ë¦½':
            return 'color: gray;'
        else:
            return ''

    def highlight_news(row):
        color = color_news(row['ë‰´ìŠ¤íŒë³„'])
        return [color] * len(row)

    st.write("### ðŸ“° ì˜¤ëŠ˜ ì¢…ëª© ë‰´ìŠ¤ ì „ì²´")
    st.dataframe(final_df.style.apply(highlight_news, axis=1), use_container_width=True)

    expecting_stocks = final_df[(final_df['ë‰´ìŠ¤íŒë³„'] == 'í˜¸ìž¬') & (final_df['ì˜ˆìƒì£¼ê°€-í˜„ìž¬ê°€'] != 'N/A')]

    def to_float(x):
        try:
            return float(str(x).replace(',', '').replace('+',''))
        except:
            return -9999999

    expecting_stocks_unique = expecting_stocks.sort_values('ì˜ˆìƒì£¼ê°€-í˜„ìž¬ê°€', ascending=False) \
                                             .drop_duplicates(subset=['ì¢…ëª©ëª…'], keep='first')

    top5_expect = expecting_stocks_unique.head(5)

    if not top5_expect.empty:
        st.write("### ðŸš€ ê°€ìž¥ ê¸°ëŒ€ë˜ëŠ” ì¢…ëª© TOP 5 (í˜¸ìž¬ + ìƒìŠ¹ì—¬ë ¥ ë†’ì€ ìˆœ)")
        st.dataframe(top5_expect[[
            'ì¢…ëª©ëª…', 'ë‰´ìŠ¤', 'ìš”ì•½', 'ë‰´ìŠ¤íŒë³„', 'AIì„¤ëª…', 'ì˜ˆìƒì£¼ê°€', 'í˜„ìž¬ê°€', 'ì˜ˆìƒì£¼ê°€-í˜„ìž¬ê°€', 'ë§í¬'
        ]])
    else:
        st.info("í˜¸ìž¬ì— í•´ë‹¹í•˜ëŠ” ì¢…ëª©ì´ ì—†ê±°ë‚˜ ìƒìŠ¹ì—¬ë ¥ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.")

    st.write("## ðŸ“Š í˜¸ìž¬ ì¢…ëª© 20ì¼ ë³¼ë¦°ì € ë°´ë“œ ì°¨íŠ¸")
    for idx, row in expecting_stocks_unique.iterrows():
        stock_name = row['ì¢…ëª©ëª…']
        code = get_code_from_name(stock_name)
        if not code:
            st.warning(f"{stock_name} ì¢…ëª©ì½”ë“œ ì—†ìŒ, ì°¨íŠ¸ ìƒëžµ")
            continue
        try:
            df_price = crawl_naver_daily_price(code, max_days=60)
        except Exception as e:
            st.warning(f"{stock_name} ì‹œì„¸ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            continue

        news_dates_for_stock = news_df[
            (news_df['ì¢…ëª©ëª…'] == stock_name) & (news_df['ë‰´ìŠ¤íŒë³„'] == 'í˜¸ìž¬')
        ]['ë‰´ìŠ¤ë‚ ì§œ'].unique().tolist()

        plot_bollinger_20day(df_price, stock_name, code, key=f"bollinger_{code}_{idx}", news_dates=news_dates_for_stock)

    def to_html_download(df):
        html = df.to_html(index=False)
        b64 = html.encode('utf-8')
        return b64

    b64_html = to_html_download(final_df)
    st.download_button(
        label="ðŸ“¥ HTML ë‹¤ìš´ë¡œë“œ",
        data=b64_html,
        file_name="stock_news_ai_result.html",
        mime="text/html"
    )

    st.session_state.is_running = False
